{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bbc-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>tv futur hand viewer home theatr system plasma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>worldcom boss left book alon former worldcom b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tiger wari farrel gambl leicest say rush make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>yead face newcastl fa cup premiership side new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ocean twelv raid box offic ocean twelv crime c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>howard hit back mongrel jibe michael howard ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>blair prepar name poll date toni blair like na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>henman hope end dubai third seed tim henman sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>wilkinson fit face edinburgh england captain j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>last star war children sixth final star war mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               text\n",
       "0         4  tv futur hand viewer home theatr system plasma...\n",
       "1         0  worldcom boss left book alon former worldcom b...\n",
       "2         3  tiger wari farrel gambl leicest say rush make ...\n",
       "3         3  yead face newcastl fa cup premiership side new...\n",
       "4         1  ocean twelv raid box offic ocean twelv crime c...\n",
       "5         2  howard hit back mongrel jibe michael howard ha...\n",
       "6         2  blair prepar name poll date toni blair like na...\n",
       "7         3  henman hope end dubai third seed tim henman sl...\n",
       "8         3  wilkinson fit face edinburgh england captain j...\n",
       "9         1  last star war children sixth final star war mo..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2225</td>\n",
       "      <td>2225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>2126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>sport</td>\n",
       "      <td>jobs growth still slow in the us the us create...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>511</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                               text\n",
       "count      2225                                               2225\n",
       "unique        5                                               2126\n",
       "top       sport  jobs growth still slow in the us the us create...\n",
       "freq        511                                                  2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')   # get NLTK library\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'want', 'to', 'kiss', 'his', 'girlfriend']\n",
      "want\n",
      "kiss\n",
      "girlfriend\n"
     ]
    }
   ],
   "source": [
    "kalimat = 'he want to kiss his girlfriend'\n",
    "kalimat = word_tokenize(kalimat)\n",
    "print(kalimat)\n",
    "for kata in kalimat:\n",
    "    if kata not in stop_words:\n",
    "        print(kata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data['text'])):  #perulangan sebanyak text\n",
    "    new_article = ''   #membuat template artikel baru \n",
    "    article = word_tokenize(data['text'][i])   #potong artikel menjadi per-kata\n",
    "    for word in article : #perulangan untuk setiap kaya\n",
    "        word = word.lower()  #jadikan huruf kecil\n",
    "        word = ps.stem(word) #ngebalikin ke kata dasar\n",
    "        if word not in stop_words and len(word)>1 and word.isalpha():  #menghapus stopwords\n",
    "            new_article = new_article + word + ' '\n",
    "    data['text'][i] = new_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "kelas = list(data['category'].unique())   #me-list text nya\n",
    "\n",
    "le.fit(kelas)    #ngasih pelabelan \n",
    "data['category'] = le.transform(data['category'])  #merubah menjadi angka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #memotong data text dan kategori tadi\n",
    "#x : data, y :kelas\n",
    "X_train, X_test, y_train, y_test = train_test_split(matriks_vector, data['category'], test_size=0.33, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()  #ngitung jumlah kata - kata yg muncul dalam suatu artikel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "matriks_vector = vectorizer.fit_transform(data['text'])\n",
    "print(matriks_vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aac',\n",
       " 'aadc',\n",
       " 'aaltra',\n",
       " 'aan',\n",
       " 'aarhu',\n",
       " 'aaron',\n",
       " 'abacu',\n",
       " 'abandon',\n",
       " 'abat',\n",
       " 'abba',\n",
       " 'abbasi',\n",
       " 'abbey',\n",
       " 'abbott',\n",
       " 'abbrevi',\n",
       " 'abc',\n",
       " 'abd',\n",
       " 'abdellatif',\n",
       " 'abdic',\n",
       " 'abdomen',\n",
       " 'abdomin',\n",
       " 'abdul',\n",
       " 'abdullah',\n",
       " 'abeb',\n",
       " 'abensur',\n",
       " 'aberdeen',\n",
       " 'aberr',\n",
       " 'abey',\n",
       " 'abeyi',\n",
       " 'abhorr',\n",
       " 'abid',\n",
       " 'abigail',\n",
       " 'abil',\n",
       " 'abiyot',\n",
       " 'abl',\n",
       " 'abn',\n",
       " 'abnorm',\n",
       " 'abolish',\n",
       " 'abolit',\n",
       " 'abort',\n",
       " 'abortionist',\n",
       " 'abov',\n",
       " 'abraham',\n",
       " 'abramovich',\n",
       " 'abroad',\n",
       " 'abruptli',\n",
       " 'absa',\n",
       " 'absenc',\n",
       " 'absent',\n",
       " 'absolut',\n",
       " 'absorb',\n",
       " 'abstain',\n",
       " 'abstent',\n",
       " 'absurd',\n",
       " 'abtahi',\n",
       " 'abu',\n",
       " 'abund',\n",
       " 'aburiz',\n",
       " 'abut',\n",
       " 'abuzz',\n",
       " 'abysm',\n",
       " 'ac',\n",
       " 'academ',\n",
       " 'academi',\n",
       " 'acapulco',\n",
       " 'acc',\n",
       " 'accel',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessori',\n",
       " 'accid',\n",
       " 'acclaim',\n",
       " 'acclim',\n",
       " 'acclimati',\n",
       " 'accolad',\n",
       " 'accommod',\n",
       " 'accomod',\n",
       " 'accompani',\n",
       " 'accompl',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'accordingli',\n",
       " 'account',\n",
       " 'accoust',\n",
       " 'accra',\n",
       " 'accret',\n",
       " 'accu',\n",
       " 'accumul',\n",
       " 'accur',\n",
       " 'accuraci',\n",
       " 'accustom',\n",
       " 'ace',\n",
       " 'aceh',\n",
       " 'achiev',\n",
       " 'achik',\n",
       " 'achil',\n",
       " 'achtung',\n",
       " 'acid',\n",
       " 'acknowledg',\n",
       " 'acoust',\n",
       " 'acquir',\n",
       " 'acquisit',\n",
       " 'acquit',\n",
       " 'acr',\n",
       " 'acrimoni',\n",
       " 'acrobat',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'activi',\n",
       " 'activison',\n",
       " 'activist',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'acupunctur',\n",
       " 'ad',\n",
       " 'adair',\n",
       " 'adam',\n",
       " 'adamind',\n",
       " 'adamu',\n",
       " 'adapt',\n",
       " 'adaptor',\n",
       " 'adb',\n",
       " 'add',\n",
       " 'addick',\n",
       " 'addict',\n",
       " 'addink',\n",
       " 'addison',\n",
       " 'addit',\n",
       " 'address',\n",
       " 'adductor',\n",
       " 'adelaid',\n",
       " 'adept',\n",
       " 'adequ',\n",
       " 'ader',\n",
       " 'adera',\n",
       " 'adher',\n",
       " 'adhi',\n",
       " 'adict',\n",
       " 'adida',\n",
       " 'adjourn',\n",
       " 'adjud',\n",
       " 'adjust',\n",
       " 'administ',\n",
       " 'administr',\n",
       " 'admir',\n",
       " 'admiss',\n",
       " 'admit',\n",
       " 'admonish',\n",
       " 'ado',\n",
       " 'adolesc',\n",
       " 'adolf',\n",
       " 'adopt',\n",
       " 'ador',\n",
       " 'adorn',\n",
       " 'adrenalin',\n",
       " 'adrian',\n",
       " 'adriano',\n",
       " 'adriat',\n",
       " 'adroit',\n",
       " 'adsen',\n",
       " 'adsl',\n",
       " 'adss',\n",
       " 'adult',\n",
       " 'adulteri',\n",
       " 'adulthood',\n",
       " 'advanc',\n",
       " 'advanta',\n",
       " 'advantag',\n",
       " 'advent',\n",
       " 'adventur',\n",
       " 'adver',\n",
       " 'advert',\n",
       " 'adverti',\n",
       " 'advi',\n",
       " 'advic',\n",
       " 'advisor',\n",
       " 'advisori',\n",
       " 'advoc',\n",
       " 'advocaci',\n",
       " 'adwar',\n",
       " 'ae',\n",
       " 'aefa',\n",
       " 'aer',\n",
       " 'aero',\n",
       " 'aeronaut',\n",
       " 'aeroplan',\n",
       " 'aerosmith',\n",
       " 'aerospac',\n",
       " 'aesthet',\n",
       " 'affabl',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'afficiando',\n",
       " 'affili',\n",
       " 'affirm',\n",
       " 'afflict',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afi',\n",
       " 'afield',\n",
       " 'afloat',\n",
       " 'afoot',\n",
       " 'afp',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afro',\n",
       " 'aftenposten',\n",
       " 'afterlif',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'afteward',\n",
       " 'ag',\n",
       " 'agassi',\n",
       " 'age',\n",
       " 'ageism',\n",
       " 'agenc',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggarw',\n",
       " 'aggrav',\n",
       " 'aggreg',\n",
       " 'aggress',\n",
       " 'aggressor',\n",
       " 'aggriev',\n",
       " 'agil',\n",
       " 'agio',\n",
       " 'agit',\n",
       " 'agm',\n",
       " 'agn',\n",
       " 'agnelli',\n",
       " 'agnost',\n",
       " 'ago',\n",
       " 'agoa',\n",
       " 'agoni',\n",
       " 'agonisingli',\n",
       " 'agoy',\n",
       " 'agr',\n",
       " 'agreeabl',\n",
       " 'agreement',\n",
       " 'agricultur',\n",
       " 'agrochem',\n",
       " 'agua',\n",
       " 'aguilera',\n",
       " 'agustin',\n",
       " 'agyemang',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahern',\n",
       " 'ahhhh',\n",
       " 'ahm',\n",
       " 'ahold',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aidan',\n",
       " 'aiden',\n",
       " 'aig',\n",
       " 'ail',\n",
       " 'aim',\n",
       " 'aimlessli',\n",
       " 'aiport',\n",
       " 'air',\n",
       " 'airasia',\n",
       " 'airbrush',\n",
       " 'airbu',\n",
       " 'aircraft',\n",
       " 'airi',\n",
       " 'airlin',\n",
       " 'airplan',\n",
       " 'airplay',\n",
       " 'airport',\n",
       " 'airtim',\n",
       " 'airway',\n",
       " 'aishwariya',\n",
       " 'aitken',\n",
       " 'aiyar',\n",
       " 'aizlewood',\n",
       " 'ajar',\n",
       " 'ajax',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akaev',\n",
       " 'akamai',\n",
       " 'akhmetov',\n",
       " 'akin',\n",
       " 'akira',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'aladdin',\n",
       " 'alain',\n",
       " 'alamo',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alastair',\n",
       " 'alb',\n",
       " 'albacet',\n",
       " 'albani',\n",
       " 'albania',\n",
       " 'albanian',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'alberto',\n",
       " 'albion',\n",
       " 'album',\n",
       " 'alcatel',\n",
       " 'alcock',\n",
       " 'alcohol',\n",
       " 'alcorn',\n",
       " 'alda',\n",
       " 'aldershot',\n",
       " 'alec',\n",
       " 'alegr',\n",
       " 'aleksey',\n",
       " 'alencar',\n",
       " 'alert',\n",
       " 'alessandro',\n",
       " 'alex',\n",
       " 'alexand',\n",
       " 'alexandra',\n",
       " 'alexei',\n",
       " 'alfa',\n",
       " 'alfonso',\n",
       " 'alfr',\n",
       " 'algemeen',\n",
       " 'algeria',\n",
       " 'algerian',\n",
       " 'algorithm',\n",
       " 'ali',\n",
       " 'alia',\n",
       " 'aliadi',\n",
       " 'alic',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'alienwar',\n",
       " 'alight',\n",
       " 'align',\n",
       " 'alik',\n",
       " 'alison',\n",
       " 'alistair',\n",
       " 'alita',\n",
       " 'alitalia',\n",
       " 'aliv',\n",
       " 'allahgreen',\n",
       " 'allair',\n",
       " 'allan',\n",
       " 'allard',\n",
       " 'allardyc',\n",
       " 'allawi',\n",
       " 'allay',\n",
       " 'alleg',\n",
       " 'allegedli',\n",
       " 'allegi',\n",
       " 'allen',\n",
       " 'allend',\n",
       " 'allevi',\n",
       " 'alley',\n",
       " 'alleyn',\n",
       " 'alli',\n",
       " 'allianc',\n",
       " 'allianz',\n",
       " 'allist',\n",
       " 'alloc',\n",
       " 'allot',\n",
       " 'allow',\n",
       " 'alloway',\n",
       " 'allsop',\n",
       " 'alltel',\n",
       " 'allud',\n",
       " 'allur',\n",
       " 'allyn',\n",
       " 'almagro',\n",
       " 'almeria',\n",
       " 'almodovar',\n",
       " 'almost',\n",
       " 'almunia',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alongsid',\n",
       " 'alonso',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alphabet',\n",
       " 'alpin',\n",
       " 'alreadi',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'altavista',\n",
       " 'alter',\n",
       " 'alterc',\n",
       " 'altern',\n",
       " 'although',\n",
       " 'alto',\n",
       " 'altogeth',\n",
       " 'altria',\n",
       " 'aluminium',\n",
       " 'alun',\n",
       " 'alvarez',\n",
       " 'alvin',\n",
       " 'alwal',\n",
       " 'alway',\n",
       " 'alwi',\n",
       " 'alyn',\n",
       " 'alyona',\n",
       " 'alzheim',\n",
       " 'ama',\n",
       " 'amadeu',\n",
       " 'amalgam',\n",
       " 'amalr',\n",
       " 'amanda',\n",
       " 'amankwaah',\n",
       " 'amarishi',\n",
       " 'amass',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amaz',\n",
       " 'amazingli',\n",
       " 'amazon',\n",
       " 'ambani',\n",
       " 'ambassador',\n",
       " 'amber',\n",
       " 'ambient',\n",
       " 'ambigu',\n",
       " 'ambit',\n",
       " 'ambiti',\n",
       " 'ambo',\n",
       " 'ambro',\n",
       " 'ambuja',\n",
       " 'ambul',\n",
       " 'amd',\n",
       " 'ame',\n",
       " 'amelia',\n",
       " 'amen',\n",
       " 'amend',\n",
       " 'ameobi',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americani',\n",
       " 'amex',\n",
       " 'amey',\n",
       " 'amf',\n",
       " 'ami',\n",
       " 'amibit',\n",
       " 'amic',\n",
       " 'amicu',\n",
       " 'amid',\n",
       " 'amiga',\n",
       " 'amin',\n",
       " 'amit',\n",
       " 'amitai',\n",
       " 'amma',\n",
       " 'ammunit',\n",
       " 'amnesti',\n",
       " 'amoah',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amor',\n",
       " 'amorebieta',\n",
       " 'amoruso',\n",
       " 'amount',\n",
       " 'ampa',\n",
       " 'ampl',\n",
       " 'ampli',\n",
       " 'amplif',\n",
       " 'amplifi',\n",
       " 'amr',\n",
       " 'amritsar',\n",
       " 'amro',\n",
       " 'amstel',\n",
       " 'amsterdam',\n",
       " 'amu',\n",
       " 'amuro',\n",
       " 'amusategui',\n",
       " 'ana',\n",
       " 'anakin',\n",
       " 'anali',\n",
       " 'analog',\n",
       " 'analogu',\n",
       " 'analsyt',\n",
       " 'analysi',\n",
       " 'analyst',\n",
       " 'analyt',\n",
       " 'analyz',\n",
       " 'anand',\n",
       " 'anastacia',\n",
       " 'anastasia',\n",
       " 'anathema',\n",
       " 'anatomi',\n",
       " 'ancelotti',\n",
       " 'ancestor',\n",
       " 'anchor',\n",
       " 'ancic',\n",
       " 'ancient',\n",
       " 'ancillari',\n",
       " 'ancram',\n",
       " 'ander',\n",
       " 'anderlecht',\n",
       " 'andersen',\n",
       " 'anderson',\n",
       " 'anderton',\n",
       " 'andhra',\n",
       " 'andi',\n",
       " 'andr',\n",
       " 'andrad',\n",
       " 'andrea',\n",
       " 'andreev',\n",
       " 'andrei',\n",
       " 'andrew',\n",
       " 'andrey',\n",
       " 'andriy',\n",
       " 'anecdot',\n",
       " 'anelka',\n",
       " 'aneurysm',\n",
       " 'anew',\n",
       " 'anfield',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angelina',\n",
       " 'anger',\n",
       " 'angi',\n",
       " 'angl',\n",
       " 'angler',\n",
       " 'anglesea',\n",
       " 'anglia',\n",
       " 'anglian',\n",
       " 'anglican',\n",
       " 'angola',\n",
       " 'angolan',\n",
       " 'angri',\n",
       " 'angrili',\n",
       " 'angst',\n",
       " 'ani',\n",
       " 'anil',\n",
       " 'anim',\n",
       " 'animo',\n",
       " 'aniston',\n",
       " 'anita',\n",
       " 'ankara',\n",
       " 'ankl',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annabella',\n",
       " 'annad',\n",
       " 'annal',\n",
       " 'annett',\n",
       " 'anni',\n",
       " 'anniversari',\n",
       " 'annouc',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'annoyingli',\n",
       " 'annual',\n",
       " 'annuali',\n",
       " 'annuiti',\n",
       " 'annul',\n",
       " 'anomali',\n",
       " 'anonym',\n",
       " 'anoth',\n",
       " 'anounc',\n",
       " 'anselmo',\n",
       " 'ansheng',\n",
       " 'anson',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'antenna',\n",
       " 'anthem',\n",
       " 'anthoni',\n",
       " 'anti',\n",
       " 'antibacteri',\n",
       " 'antibiot',\n",
       " 'antic',\n",
       " 'anticip',\n",
       " 'antiqu',\n",
       " 'antitrust',\n",
       " 'antoin',\n",
       " 'antoinett',\n",
       " 'anton',\n",
       " 'antoni',\n",
       " 'antonio',\n",
       " 'anurag',\n",
       " 'anxieti',\n",
       " 'anxiou',\n",
       " 'anybodi',\n",
       " 'anyht',\n",
       " 'anyinsah',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'anytim',\n",
       " 'anyway',\n",
       " 'anywh',\n",
       " 'aol',\n",
       " 'aon',\n",
       " 'ap',\n",
       " 'apac',\n",
       " 'apach',\n",
       " 'apal',\n",
       " 'apart',\n",
       " 'apartheid',\n",
       " 'apathet',\n",
       " 'apathi',\n",
       " 'apcom',\n",
       " 'ape',\n",
       " 'apiec',\n",
       " 'apollo',\n",
       " 'apolog',\n",
       " 'app',\n",
       " 'appal',\n",
       " 'appar',\n",
       " 'apparatu',\n",
       " 'apparel',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appela',\n",
       " 'appetit',\n",
       " 'appl',\n",
       " 'applau',\n",
       " 'applaud',\n",
       " 'appleford',\n",
       " 'appleg',\n",
       " 'appleton',\n",
       " 'appli',\n",
       " 'applianc',\n",
       " 'applic',\n",
       " 'appoint',\n",
       " 'apport',\n",
       " 'apprai',\n",
       " 'appreci',\n",
       " 'apprehen',\n",
       " 'apprehend',\n",
       " 'apprent',\n",
       " 'apprenticeship',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approv',\n",
       " 'approxim',\n",
       " 'april',\n",
       " 'apurva',\n",
       " 'aquariu',\n",
       " 'aquat',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arafat',\n",
       " 'aragon',\n",
       " 'aramburu',\n",
       " 'arash',\n",
       " 'arbit',\n",
       " 'arbitr',\n",
       " 'arbitrari',\n",
       " 'arbitrarili',\n",
       " 'arbor',\n",
       " 'arcad',\n",
       " 'arch',\n",
       " 'archangel',\n",
       " 'archbishop',\n",
       " 'archer',\n",
       " 'archi',\n",
       " 'archibald',\n",
       " 'architect',\n",
       " 'architectur',\n",
       " 'archiv',\n",
       " 'archivist',\n",
       " 'archo',\n",
       " 'arci',\n",
       " 'ardent',\n",
       " 'arditti',\n",
       " 'arduou',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'aretha',\n",
       " 'argentin',\n",
       " 'argentina',\n",
       " 'argonaut',\n",
       " 'argu',\n",
       " 'arguabl',\n",
       " 'argument',\n",
       " 'argyl',\n",
       " 'ari',\n",
       " 'ariadn',\n",
       " 'ariari',\n",
       " 'ariel',\n",
       " 'arima',\n",
       " 'arisen',\n",
       " 'arizona',\n",
       " 'arjan',\n",
       " 'arjen',\n",
       " 'arkansa',\n",
       " 'arlington',\n",
       " 'arm',\n",
       " 'armagh',\n",
       " 'armand',\n",
       " 'armando',\n",
       " 'armani',\n",
       " 'armband',\n",
       " 'armenian',\n",
       " 'armenti',\n",
       " 'armi',\n",
       " 'armistead',\n",
       " 'armour',\n",
       " 'armouri',\n",
       " 'armstrong',\n",
       " 'arn',\n",
       " 'arnaud',\n",
       " 'arnesen',\n",
       " 'arnold',\n",
       " 'arnoud',\n",
       " 'arou',\n",
       " 'around',\n",
       " 'arpey',\n",
       " 'arquett',\n",
       " 'arr',\n",
       " 'arrang',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arrigo',\n",
       " 'arriv',\n",
       " 'arrog',\n",
       " 'arrogantli',\n",
       " 'arron',\n",
       " 'arsen',\n",
       " 'arsenid',\n",
       " 'arson',\n",
       " 'art',\n",
       " 'artel',\n",
       " 'arteri',\n",
       " 'arteta',\n",
       " 'artgarden',\n",
       " 'arthriti',\n",
       " 'arthur',\n",
       " 'arti',\n",
       " 'artic',\n",
       " 'articl',\n",
       " 'articul',\n",
       " 'artif',\n",
       " 'artifici',\n",
       " 'artist',\n",
       " 'artistri',\n",
       " 'arturo',\n",
       " 'artwork',\n",
       " 'aru',\n",
       " 'arundel',\n",
       " 'arvind',\n",
       " 'asago',\n",
       " 'asant',\n",
       " 'asbesto',\n",
       " 'asbestosi',\n",
       " 'ascend',\n",
       " 'ascii',\n",
       " 'ash',\n",
       " 'asha',\n",
       " 'asham',\n",
       " 'ashburton',\n",
       " 'ashcroft',\n",
       " 'asher',\n",
       " 'ashfield',\n",
       " 'ashia',\n",
       " 'ashley',\n",
       " 'ashok',\n",
       " 'ashton',\n",
       " 'ashvin',\n",
       " 'asi',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asid',\n",
       " 'asif',\n",
       " 'asimo',\n",
       " 'ask',\n",
       " 'askar',\n",
       " 'aspect',\n",
       " 'asper',\n",
       " 'asphalt',\n",
       " 'aspir',\n",
       " 'asplin',\n",
       " 'ass',\n",
       " 'assad',\n",
       " 'assassin',\n",
       " 'assault',\n",
       " 'assembl',\n",
       " 'assert',\n",
       " 'assess',\n",
       " 'asset',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'assort',\n",
       " 'assum',\n",
       " 'assumpt',\n",
       " 'assur',\n",
       " 'astel',\n",
       " 'asteroid',\n",
       " 'astiazaran',\n",
       " 'aston',\n",
       " 'astonish',\n",
       " 'astonishingli',\n",
       " 'astoria',\n",
       " 'astound',\n",
       " 'astra',\n",
       " 'astrazeneca',\n",
       " 'astronom',\n",
       " 'asylum',\n",
       " 'asymmetr',\n",
       " 'asymmetri',\n",
       " 'atari',\n",
       " 'ate',\n",
       " 'athen',\n",
       " 'athlet',\n",
       " 'athlon',\n",
       " 'ati',\n",
       " 'atinc',\n",
       " 'atkin',\n",
       " 'atkinson',\n",
       " 'atla',\n",
       " 'atlabour',\n",
       " 'atlant',\n",
       " 'atletico',\n",
       " 'atm',\n",
       " 'atmosph',\n",
       " 'ato',\n",
       " 'atom',\n",
       " 'atomstroieksport',\n",
       " 'atp',\n",
       " 'atr',\n",
       " 'atrium',\n",
       " 'att',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attain',\n",
       " 'attallah',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attest',\n",
       " 'atticu',\n",
       " 'attitud',\n",
       " 'attl',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attribut',\n",
       " 'au',\n",
       " 'aubrey',\n",
       " 'auckland',\n",
       " 'auction',\n",
       " 'audi',\n",
       " 'audienc',\n",
       " 'audio',\n",
       " 'audioblog',\n",
       " 'audiovisuel',\n",
       " 'audit',\n",
       " 'auditor',\n",
       " 'audrey',\n",
       " 'auf',\n",
       " 'august',\n",
       " 'augusto',\n",
       " 'auld',\n",
       " 'auli',\n",
       " 'aunt',\n",
       " 'aurelien',\n",
       " 'auschwitz',\n",
       " 'aussi',\n",
       " 'austin',\n",
       " 'australasia',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'austria',\n",
       " 'austrian',\n",
       " 'auteuil',\n",
       " 'authent',\n",
       " 'author',\n",
       " 'authori',\n",
       " 'authoritarian',\n",
       " 'authorship',\n",
       " 'autist',\n",
       " 'auto',\n",
       " 'autobiograph',\n",
       " 'autograph',\n",
       " 'autolink',\n",
       " 'autom',\n",
       " 'automat',\n",
       " 'automobil',\n",
       " 'automot',\n",
       " 'autumn',\n",
       " 'auvergn',\n",
       " 'auxerr',\n",
       " 'avail',\n",
       " 'avalanch',\n",
       " 'avatar',\n",
       " 'avenu',\n",
       " 'averag',\n",
       " 'avert',\n",
       " 'avg',\n",
       " 'avi',\n",
       " 'aviat',\n",
       " 'avid',\n",
       " 'avion',\n",
       " 'aviv',\n",
       " 'avoid',\n",
       " 'avril',\n",
       " 'aw',\n",
       " 'await',\n",
       " 'awaken',\n",
       " 'awar',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awesom',\n",
       " 'awkward',\n",
       " 'awoken',\n",
       " 'awol',\n",
       " 'axa',\n",
       " 'axe',\n",
       " 'axi',\n",
       " 'ayaan',\n",
       " 'ayatollah',\n",
       " 'ayer',\n",
       " 'az',\n",
       " 'azim',\n",
       " 'azkaban',\n",
       " 'azmat',\n",
       " 'aztrazeneca',\n",
       " 'azzam',\n",
       " 'azzurri',\n",
       " 'ba',\n",
       " 'baa',\n",
       " 'baathist',\n",
       " 'babacan',\n",
       " 'babayaro',\n",
       " 'babi',\n",
       " 'babinet',\n",
       " 'babyshambl',\n",
       " 'babysitt',\n",
       " 'bac',\n",
       " 'bacap',\n",
       " 'baccarat',\n",
       " 'bach',\n",
       " 'back',\n",
       " 'backbench',\n",
       " 'backbon',\n",
       " 'backdoor',\n",
       " 'backdrop',\n",
       " 'backer',\n",
       " 'backfir',\n",
       " 'background',\n",
       " 'backhand',\n",
       " 'backlash',\n",
       " 'backley',\n",
       " 'backlog',\n",
       " 'backroom',\n",
       " 'backsid',\n",
       " 'backslid',\n",
       " 'backstag',\n",
       " 'backstreet',\n",
       " 'backtrack',\n",
       " 'backup',\n",
       " 'backward',\n",
       " 'backyard',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'baddeley',\n",
       " 'badg',\n",
       " 'badger',\n",
       " 'badli',\n",
       " 'bae',\n",
       " 'baffl',\n",
       " 'bafin',\n",
       " 'bafta',\n",
       " 'bag',\n",
       " 'baggag',\n",
       " 'baggin',\n",
       " 'baghdad',\n",
       " 'bagl',\n",
       " 'baglihar',\n",
       " 'bagnato',\n",
       " 'bagpuss',\n",
       " 'baha',\n",
       " 'bahama',\n",
       " 'bahoken',\n",
       " 'baht',\n",
       " 'baikal',\n",
       " 'bail',\n",
       " 'bailey',\n",
       " 'bailiff',\n",
       " 'bailin',\n",
       " 'bailout',\n",
       " 'bainivalu',\n",
       " 'bait',\n",
       " 'bak',\n",
       " 'baker',\n",
       " 'bakersfield',\n",
       " 'bakri',\n",
       " 'bakula',\n",
       " 'balado',\n",
       " 'balagu',\n",
       " 'balamori',\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names() #ngelihat colomn katanya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "matriks_vector_test = vectorizer.fit_transform(X_test)\n",
    "print(matriks_vector_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train.toarray(), y_train)  # Naive bayes belajar, dari data x_train, jawabannya categori y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 3, 3, 1, 3, 3, 4, 3, 2, 3, 4, 3, 3, 4, 1, 4, 2, 4, 1, 0, 0,\n",
       "       3, 4, 2, 3, 4, 0, 3, 4, 3, 0, 3, 1, 0, 1, 3, 0, 0, 2, 3, 0, 1, 1,\n",
       "       3, 2, 4, 4, 4, 4, 3, 3, 3, 1, 3, 3, 0, 2, 1, 0, 2, 0, 0, 3, 2, 3,\n",
       "       3, 0, 4, 2, 2, 3, 0, 2, 0, 4, 4, 1, 3, 2, 3, 3, 2, 2, 2, 3, 2, 1,\n",
       "       2, 2, 1, 1, 4, 2, 3, 2, 1, 0, 4, 1, 1, 2, 4, 2, 2, 1, 1, 4, 2, 0,\n",
       "       3, 1, 3, 2, 4, 3, 2, 2, 3, 3, 3, 4, 1, 0, 0, 0, 0, 1, 4, 3, 2, 1,\n",
       "       0, 1, 4, 1, 2, 0, 2, 1, 3, 0, 3, 0, 0, 3, 0, 3, 0, 4, 1, 4, 0, 1,\n",
       "       0, 2, 3, 2, 0, 2, 0, 2, 3, 3, 2, 2, 0, 3, 4, 4, 2, 0, 0, 1, 0, 3,\n",
       "       2, 1, 3, 4, 2, 2, 1, 1, 3, 0, 1, 3, 0, 0, 4, 2, 4, 2, 3, 2, 0, 3,\n",
       "       0, 0, 2, 0, 2, 2, 2, 0, 4, 3, 4, 3, 0, 3, 4, 1, 2, 0, 1, 0, 1, 0,\n",
       "       4, 0, 2, 1, 1, 1, 3, 3, 0, 1, 3, 4, 0, 4, 3, 1, 3, 2, 4, 3, 1, 2,\n",
       "       4, 3, 3, 1, 2, 1, 1, 0, 3, 1, 4, 2, 4, 2, 1, 4, 1, 4, 0, 1, 3, 4,\n",
       "       2, 0, 0, 0, 2, 2, 0, 1, 2, 2, 0, 3, 2, 2, 4, 0, 4, 2, 2, 4, 0, 3,\n",
       "       2, 1, 0, 0, 3, 0, 4, 3, 0, 1, 1, 2, 4, 2, 3, 4, 0, 0, 2, 4, 2, 0,\n",
       "       0, 2, 4, 3, 2, 1, 1, 3, 1, 3, 1, 0, 2, 0, 1, 4, 4, 1, 1, 2, 0, 3,\n",
       "       1, 0, 2, 1, 4, 2, 3, 2, 3, 1, 4, 4, 1, 3, 0, 2, 1, 3, 2, 0, 1, 4,\n",
       "       0, 1, 0, 4, 1, 1, 4, 4, 1, 2, 4, 0, 0, 2, 4, 3, 4, 0, 2, 1, 4, 0,\n",
       "       3, 3, 0, 0, 2, 3, 3, 1, 0, 0, 4, 0, 0, 4, 3, 0, 3, 1, 4, 2, 4, 0,\n",
       "       3, 4, 0, 2, 4, 2, 1, 4, 3, 4, 4, 4, 3, 0, 1, 2, 1, 3, 0, 4, 3, 0,\n",
       "       4, 2, 4, 3, 0, 2, 1, 3, 4, 2, 2, 2, 4, 2, 4, 0, 0, 1, 2, 4, 0, 1,\n",
       "       0, 3, 2, 1, 1, 1, 1, 2, 3, 3, 3, 4, 3, 4, 3, 0, 2, 2, 2, 0, 2, 1,\n",
       "       0, 1, 2, 1, 0, 2, 3, 1, 2, 0, 3, 3, 4, 2, 4, 0, 0, 3, 4, 3, 0, 2,\n",
       "       2, 1, 3, 3, 4, 1, 1, 1, 4, 3, 3, 2, 4, 2, 3, 4, 3, 1, 1, 2, 3, 3,\n",
       "       3, 2, 0, 2, 0, 4, 3, 2, 3, 2, 3, 2, 4, 2, 4, 3, 0, 3, 4, 0, 4, 1,\n",
       "       1, 4, 2, 3, 0, 0, 1, 2, 0, 0, 4, 3, 1, 0, 1, 1, 3, 4, 1, 3, 4, 1,\n",
       "       1, 4, 0, 2, 3, 2, 0, 3, 4, 3, 0, 3, 3, 3, 3, 0, 4, 0, 3, 2, 3, 0,\n",
       "       4, 0, 1, 1, 1, 4, 3, 3, 3, 1, 3, 3, 1, 0, 4, 2, 2, 0, 4, 4, 0, 1,\n",
       "       4, 0, 4, 0, 4, 3, 2, 0, 2, 3, 1, 4, 2, 1, 4, 0, 0, 0, 0, 1, 3, 4,\n",
       "       3, 2, 0, 1, 3, 0, 1, 0, 4, 4, 0, 3, 2, 3, 1, 1, 1, 3, 2, 0, 2, 3,\n",
       "       0, 1, 2, 4, 1, 0, 3, 4, 2, 1, 4, 2, 3, 1, 4, 0, 3, 3, 1, 4, 0, 0,\n",
       "       0, 0, 1, 4, 3, 3, 0, 1, 0, 0, 0, 1, 4, 4, 3, 4, 1, 3, 0, 0, 0, 0,\n",
       "       1, 2, 3, 3, 1, 0, 1, 2, 3, 3, 0, 2, 2, 3, 4, 2, 0, 4, 2, 3, 1, 2,\n",
       "       3, 1, 0, 0, 1, 4, 1, 0, 2, 0, 0, 0, 2, 2, 3, 4, 1, 2, 4, 1, 0, 4,\n",
       "       3, 4, 2, 2, 2, 0, 4, 4, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.87074829931973"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test.toarray(),y_test) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
